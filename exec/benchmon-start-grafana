#!/usr/bin/env python3

import argparse
import json
import os
import socket
import subprocess
import sys
import time
from pathlib import Path
import requests
from requests.auth import HTTPBasicAuth
import logging


# Get application paths from environment variables, with sensible defaults
INFLUXDB_PATH = os.environ.get("BENCHMON_INFLUXDB_PATH", "./benchmon-stack/influxdb3")
GRAFANA_PATH = os.environ.get("BENCHMON_GRAFANA_PATH", "./benchmon-stack/grafana")

INFLUXDB_BINARY = f"{INFLUXDB_PATH}/influxdb3"
GRAFANA_BINARY = f"{GRAFANA_PATH}/bin/grafana-server"

logger = logging.getLogger(__name__)

def suppress_connection_errors():
    """Temporarily suppress connection errors during wait."""
    original_log_level = logging.getLogger().getEffectiveLevel()
    logging.getLogger().setLevel(logging.CRITICAL)
    return original_log_level

def restore_log_level(original_log_level):
    """Restore the original log level."""
    logging.getLogger().setLevel(original_log_level)

def is_port_in_use(port: int) -> bool:
    """Checks if a TCP port is in use on localhost."""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        return s.connect_ex(('localhost', port)) == 0
    
def pick_available_port(requested: int, service: str) -> int:
    """Return the first free port at or above the requested value."""
    candidate = requested
    attempts = 0
    while attempts < 100 and is_port_in_use(candidate):
        logger.info(f"Port {candidate} already in use for {service}, trying {candidate + 1}...")
        candidate += 1
        attempts += 1
    if attempts >= 100:
        logger.error(f"Could not find a free port for {service} starting from {requested}.")
        sys.exit(1)
    if candidate != requested:
        logger.info(f"{service} port changed from {requested} to {candidate}.")
    return candidate

def setup_influxdb_datasource(grafana_port: int, influxdb_port: int) -> bool:
    """
    Configures Grafana to use InfluxDB as a data source.
    """

    grafana_url = f"http://localhost:{grafana_port}"

    logger.info("Waiting for Grafana to be ready...")
    original_log_level = suppress_connection_errors()

    session = requests.Session()
    session.auth = HTTPBasicAuth("admin", "admin123")

    start_time = time.time()
    grafana_ready = False
    while time.time() - start_time < 60:
        try:
            response = session.get(
                f"{grafana_url}/api/health",
                timeout=60
            )
            if response.status_code == 200:
                grafana_ready = True
                break
        except requests.RequestException:
            pass
        logger.info("Grafana not ready yet, retrying in 2 seconds...")
        time.sleep(2)

    restore_log_level(original_log_level)

    if not grafana_ready:
        logger.error("Grafana did not become available in time. Please check logs.")
        # Consider stopping the services here if Grafana fails to start
        sys.exit(1)

    logger.info("Grafana is up. Configuring datasource and dashboards...")

    # Configure datasource

    payload = {
        "name": "InfluxDB v3 SQL",
        "type": "influxdb",
        "uid": "influxdb-v3-sql",
        "access": "proxy",
        "url": f"http://localhost:{influxdb_port}",
        "basicAuth": False,
        "isDefault": True,
        "jsonData": {
            "dbName": "metrics",
            "queryLanguage": "sql",
            "version": "SQL",
            "httpMode": "GET",
            "tlsSkipVerify": True,
            "insecureConnection": True,
            "insecureGrpc": True
        },
        "secureJsonData": {}
    }

    datasource_ready = False

    response = session.get(f"{grafana_url}/api/datasources/uid/{payload['uid']}")
    if response.status_code == 200:
        logger.info("Datasource already exists, skipping creation.")
        datasource_ready = True
    else:
        response = session.post(
            f"{grafana_url}/api/datasources",
            json=payload,
            headers={"Content-Type": "application/json"}
        )
        if response.status_code in (200, 201):
            logger.info("Datasource created successfully.")
            datasource_ready = True
        else:
            logger.error(f"Error creating datasource: {response.status_code} {response.text}")

    return datasource_ready


def setup_grafana_dashboards(grafana_port: int, dashboard_dir: Path) -> bool:
    """
    Uploads dashboards from the specified directory to Grafana.
    """
    grafana_url = f"http://localhost:{grafana_port}"
    session = requests.Session()
    session.auth = HTTPBasicAuth("admin", "admin123")

    if not dashboard_dir.is_dir():
        logger.error(f"Dashboard directory {dashboard_dir} does not exist or is not a directory.")
        return False

    success = True
    for dashboard_file in dashboard_dir.glob("*.json"):
        logger.info(f"Uploading dashboard: {dashboard_file.name}")
        with open(dashboard_file, "r") as f:
            dashboard_json = json.load(f)

        payload = {
            "dashboard": dashboard_json,
            "overwrite": True,
            "message": f"Uploaded {dashboard_file} via benchmon-run-grafana"
        }

        if "id" in payload["dashboard"]:
            del payload["dashboard"]["id"]

        response = session.post(
            f"{grafana_url}/api/dashboards/db",
            json=payload,
            headers={"Content-Type": "application/json"}
        )

        if response.status_code in (200, 201):
            logger.info(f"Dashboard {dashboard_file.name} uploaded successfully.")
        else:
            logger.error(f"Error uploading dashboard {dashboard_file.name}: {response.status_code} {response.text}")
            success = False

    return success

def main():
    parser = argparse.ArgumentParser(description="Start Benchmon Grafana/InfluxDB Stack")
    parser.add_argument(
        "--save-dir",
        type=Path,
        help="Base directory for traces. Defaults to current directory."
    )
    parser.add_argument("--influxdb-port", type=int, default=8181, help="Port for InfluxDB")
    parser.add_argument("--grafana-port", type=int, default=3000, help="Port for Grafana")
    # --- MODIFICATION: Remove hardcoded default ---
    parser.add_argument(
        "--dashboard-dir",
        type=Path,
        default=None,
        help="Directory containing dashboard JSON files. Defaults to internal package dashboards."
    )
    args = parser.parse_args()

    # --- MODIFICATION: Programmatically find default dashboard directory ---
    if args.dashboard_dir is None:
        fallback_path = Path(__file__).parent.parent / "grafana" / "dashboards"
        if fallback_path.is_dir():
            args.dashboard_dir = fallback_path
            logger.info(f"--dashboard-dir not provided, using fallback development path: {args.dashboard_dir}")
  


    # --- MODIFICATION: Align directory logic with benchmon-run ---
    # The traces_dir is now the primary directory, not a subdirectory.
    traces_dir = args.save_dir if args.save_dir is not None else Path("./benchmon_traces_")
    logger.info(f"Using traces directory: {traces_dir.resolve()}")


    # 1. Prepare runtime directory inside the traces directory
    runtime_dir = traces_dir / "grafana-data"
    runtime_dir.mkdir(parents=True, exist_ok=True)

    influxdb_data_dir = runtime_dir / "influxdb_data"
    influxdb_data_dir.mkdir(exist_ok=True)

    log_dir = runtime_dir / "logs"
    log_dir.mkdir(exist_ok=True)

    # Configure logging to save to file
    log_file = log_dir / "benchmon-start-grafana.log"
    file_handler = logging.FileHandler(log_file)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)
    logger.setLevel(logging.INFO)


    pid_file = runtime_dir / "pids.json"
    connection_file = runtime_dir / "connection.json"

    # 2. Check for required binaries
    if not Path(INFLUXDB_BINARY).is_file():
        logger.error(f"InfluxDB binary not found at {INFLUXDB_BINARY}")
        logger.error("Hint: Set the BENCHMON_INFLUXDB_PATH environment variable.")
        sys.exit(1)
    if not Path(GRAFANA_BINARY).is_file():
        logger.error(f"Grafana binary not found at {GRAFANA_BINARY}")
        logger.error("Hint: Set the BENCHMON_GRAFANA_PATH environment variable.")
        sys.exit(1)

    # 3. Check ports
    if is_port_in_use(args.influxdb_port):
        logger.error(f"Port {args.influxdb_port} for InfluxDB is already in use.")
        sys.exit(1)
    if is_port_in_use(args.grafana_port):
        logger.error(f"Port {args.grafana_port} for Grafana is already in use.")
        sys.exit(1)

    pids = {}
    
    # 4. Start InfluxDB
    influxdb_port = pick_available_port(args.influxdb_port, "InfluxDB")
    logger.info(f"Starting InfluxDB on port {influxdb_port}...")
    influx_log_file = log_dir / "influxdb.log"
    
    # --- MODIFICATION: Use short hostname for node-id, like in the shell script ---
    node_id = "benchmon-node-id"
    logger.info(f"Using node-id: {node_id}")

    with open(influx_log_file, "w") as log:
        influx_process = subprocess.Popen(
            [
                INFLUXDB_BINARY, "serve",
                "--object-store", "file",
                "--node-id", node_id,
                "--http-bind", f"0.0.0.0:{influxdb_port}",
                "--data-dir", str(influxdb_data_dir),
                "--without-auth"
            ],
            stdout=log, stderr=subprocess.STDOUT
        )
    pids["influxdb"] = influx_process.pid
    logger.info(f"InfluxDB started with PID: {influx_process.pid}. Log: {influx_log_file}")

    # 5. Start Grafana
    grafana_port = pick_available_port(args.grafana_port, "Grafana")
    logger.info(f"Starting Grafana on port {grafana_port}...")
    grafana_log_file = log_dir / "grafana.log"
    with open(grafana_log_file, "w") as log:
        grafana_env = os.environ.copy()
        grafana_env.setdefault("GF_SECURITY_ADMIN_USER", "admin")
        grafana_env.setdefault("GF_SECURITY_ADMIN_PASSWORD", "admin123")
        grafana_process = subprocess.Popen(
            [GRAFANA_BINARY, f"--config={GRAFANA_PATH}/conf/defaults.ini",
             f"--homepath={GRAFANA_PATH}", f"cfg:server.http_port={grafana_port}"],
            stdout=log, stderr=subprocess.STDOUT, env=grafana_env
        )
    pids["grafana"] = grafana_process.pid
    logger.info(f"Grafana started with PID: {grafana_process.pid}. Log: {grafana_log_file}")

    # 6. Write PID and connection info files
    with open(pid_file, "w") as f:
        json.dump(pids, f)
    logger.info(f"PIDs saved to {pid_file}")

    # --- MODIFICATION: Use hostname instead of IP address ---
    hostname = socket.gethostname()
    connection_info = {
        "influxdb_url": f"http://{hostname}:{influxdb_port}",
        "grafana_url": f"http://{hostname}:{grafana_port}",
        "influxdb_token": ""  # Placeholder for token
    }
    with open(connection_file, "w") as f:
        json.dump(connection_info, f)
    logger.info(f"Connection info saved to {connection_file}")

    logger.info("\n--- Post-start Configuration ---")

    # Setup InfluxDB data source in Grafana
    if not setup_influxdb_datasource(args.grafana_port, influxdb_port):
        logger.error("Failed to set up InfluxDB data source in Grafana.")
        sys.exit(1)

    # Upload dashboards
    if not setup_grafana_dashboards(args.grafana_port, args.dashboard_dir):
        logger.error("Failed to upload one or more dashboards to Grafana.")
        sys.exit(1)

    logger.info(f"\nInfluxDB ready at http://{hostname}:{influxdb_port}")
    logger.info(f"Grafana ready at http://{hostname}:{grafana_port}\n")
    logger.info("Monitoring stack started and configured successfully.")

if __name__ == "__main__":
    main()